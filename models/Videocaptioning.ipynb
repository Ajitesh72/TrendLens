{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMSaX3kjUyFx",
        "outputId": "d65ab1ea-26ff-40c3-ace8-70d014fec50e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.5.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.62.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import av\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoTokenizer, VisionEncoderDecoderModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# load pretrained processor, tokenizer, and model\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"Neleac/timesformer-gpt2-video-captioning\").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hzrsY5mEKXr",
        "outputId": "431e88ba-3b3b-4827-c472-3323ea440109"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load video\n",
        "video_path = \"/content/Screen Recording 2024-02-05 at 9.51.51 PM.mov\"\n",
        "container = av.open(video_path)\n",
        "\n",
        "# extract evenly spaced frames from video\n",
        "seg_len = container.streams.video[0].frames\n",
        "clip_len = model.config.encoder.num_frames\n",
        "indices = set(np.linspace(0, seg_len, num=clip_len, endpoint=False).astype(np.int64))\n",
        "frames = []\n",
        "container.seek(0)\n",
        "for i, frame in enumerate(container.decode(video=0)):\n",
        "    if i in indices:\n",
        "        frames.append(frame.to_ndarray(format=\"rgb24\"))\n",
        "\n",
        "# generate caption\n",
        "gen_kwargs = {\n",
        "    \"min_length\": 10,\n",
        "    \"max_length\": 20,\n",
        "    \"num_beams\": 5,\n",
        "}\n",
        "pixel_values = image_processor(frames, return_tensors=\"pt\").pixel_values.to(device)\n",
        "tokens = model.generate(pixel_values, **gen_kwargs)\n",
        "caption = tokenizer.batch_decode(tokens, skip_special_tokens=True)[0]\n",
        "print(caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxZDkKXcFUQ6",
        "outputId": "ea3765a1-cd3b-4357-9d8e-b41bd5fd2668"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A baseball player hits a home run and the crowd cheers him on.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "HEGjrjZYUqjz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='AIzaSyAbm3aBX-y_RmdEQ5Twyx4OeVl8pBX6Ba0')\n",
        "response = genai.chat(messages=f\"Create trending hashtags according to {caption}\")\n",
        "print(response.last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "EmXcQ3SNU_qA",
        "outputId": "17650f7a-e488-4f02-c85f-915c62772412"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some trending hashtags that you can use for your post about a baseball player hitting a home run and the crowd cheering him on:\n",
            "\n",
            "* #homerun\n",
            "* #baseball\n",
            "* #mlb\n",
            "* #goteam\n",
            "* #crowdcheering\n",
            "* #sports\n",
            "* #athlete\n",
            "* #victory\n",
            "* #celebration\n",
            "* #fans\n",
            "* #gameday\n",
            "* #baseballfan\n",
            "* #baseballlife\n",
            "* #baseballlove\n",
            "* #baseballislife\n",
            "* #baseballseason\n",
            "* #baseballnation\n",
            "* #baseballfamily\n",
            "* #baseballisfun\n",
            "* #baseballisback\n",
            "* #baseballisbetterwithyou\n",
            "* #baseballismylife\n",
            "* #baseballislove\n",
            "* #baseballispassion\n",
            "* #baseballiseverything\n",
            "* #baseballislife\n",
            "* #baseballisfamily\n",
            "* #baseballisfun\n",
            "* #baseballisback\n",
            "* #baseballisbetterwithyou\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}